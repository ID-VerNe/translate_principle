# -*- coding: utf-8 -*- 

import json
from typing import List, Dict, Tuple

from .llm_client import call_llm, clean_and_extract_json
from .prompts import get_prompt_templates
# å¼•å…¥è¯­æ–™åº“ç®¡ç†å™¨
from .glossary_manager import glossary_manager

PROMPT_TEMPLATES = get_prompt_templates()

def filter_relevant_glossary(text_content: str, full_glossary: Dict[str, str]) -> Dict[str, str]:
    """
    ä»…ä¿ç•™åœ¨å½“å‰æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­ï¼Œå‡å°‘ Token æ¶ˆè€—å¹¶èšç„¦æ³¨æ„åŠ›ã€‚
    """
    relevant = {}
    text_lower = text_content.lower()
    for src, tgt in full_glossary.items():
        if src.lower() in text_lower:
            relevant[src] = tgt
    return relevant

async def extract_global_terms(config, blocks: List[Dict]) -> Dict[str, str]:
    """
    æå–æœ¯è¯­ï¼ˆæ··åˆæ¨¡å¼ï¼šå†å²è¯­æ–™åº“åŒ¹é… + LLM æ–°æœ¯è¯­å‘ç° - äº”æ­¥å¾ªç¯é‡‡æ ·ç‰ˆï¼‰
    """
    print("=== Step 1: æ„å»ºæœ¯è¯­è¡¨ (äº”æ­¥å¾ªç¯é‡‡æ ·) ===")
    
    # 1. æ‹¼æ¥å…¨æ–‡
    full_text = "\n".join([b['content'] for b in blocks])
    
    # 2. ä»å†å²è¯­æ–™åº“ä¸­åŒ¹é…
    print("  æ­£åœ¨æ£€ç´¢å†å²è¯­æ–™åº“...")
    historical_glossary = glossary_manager.extract_terms(full_text)
    print(f"  ğŸ“– åŒ¹é…åˆ° {len(historical_glossary)} ä¸ªå†å²å›ºå®šæœ¯è¯­")

    # 3. ä½¿ç”¨ LLM å‘ç°æ–°æœ¯è¯­ (äº”æ­¥å¾ªç¯é‡‡æ ·)
    print("  æ­£åœ¨ä½¿ç”¨ LLM è¿›è¡Œäº”æ­¥æ·±åº¦å‘ç°...")
    all_llm_glossary = {}
    
    # åˆ† 5 æ¬¡é‡‡æ ·ï¼Œæ¯æ¬¡èµ·ç‚¹ä¸åŒ
    for pass_idx in range(5):
        sampled_text = ""
        # æ¯æ¬¡ä» pass_idx å¼€å§‹ï¼Œæ¯ 5 è¡Œå– 1 è¡Œ
        for i in range(pass_idx, len(blocks), 5):
            sampled_text += blocks[i]['content'] + "\n"
        
        # å¦‚æœé‡‡æ ·æ–‡æœ¬è¿‡é•¿ï¼Œè¿›è¡Œåˆ‡åˆ†å¤„ç†
        # å‡è®¾å•æ¬¡æå– Prompt é™åˆ¶åœ¨çº¦ 4000 å­—ç¬¦å†…
        MAX_SAMPLE_LEN = 4000
        text_parts = [sampled_text[i:i+MAX_SAMPLE_LEN] for i in range(0, len(sampled_text), MAX_SAMPLE_LEN)]
        
        for part_idx, part_text in enumerate(text_parts):
            print(f"    - Pass {pass_idx+1}/5, Part {part_idx+1}...")
            messages = [{"role": "system", "content": PROMPT_TEMPLATES["TERM_EXTRACT"].format(content=part_text)}]
            
            result = await call_llm(config, messages, temperature=config.temp_terms)
            data = clean_and_extract_json(result)
            if isinstance(data, dict):
                all_llm_glossary.update(data)
    
    print(f"  ğŸ¤– LLM å‘ç°äº† {len(all_llm_glossary)} ä¸ªæ½œåœ¨æœ¯è¯­")

    # 4. åˆå¹¶æœ¯è¯­è¡¨å¹¶æŒä¹…åŒ–
    # ç­–ç•¥ï¼šå†å²æœ¯è¯­è¦†ç›– LLM æå–çš„æœ¯è¯­ (History is Truth)
    final_glossary = {**all_llm_glossary, **historical_glossary}
    
    # å°†æ–°å‘ç°çš„æœ¯è¯­ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“ï¼Œä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
    if all_llm_glossary:
        glossary_manager.save_terms(all_llm_glossary)
        print(f"  ğŸ’¾ å·²å°† {len(all_llm_glossary)} ä¸ªæ–°æœ¯è¯­åŒæ­¥è‡³æœ¬åœ°è¯­æ–™åº“æ•°æ®åº“")
    
    print(f"  âœ… æœ€ç»ˆæœ¯è¯­è¡¨åŒ…å« {len(final_glossary)} æ¡ç›®")
    return final_glossary


async def process_literal_stage(batch_blocks: List[Dict], config, glossary: Dict[str, str]) -> Tuple[Dict[str, str], str]:
    """
    é˜¶æ®µ1ï¼šç›´è¯‘ä¸æœ¯è¯­å‡†å¤‡ï¼ˆä¸Šä¸‹æ–‡æ— å…³ï¼Œå¯å¹¶è¡Œï¼‰
    è¿”å›: (literal_map, glossary_text)
    """
    # --- 0. åŠ¨æ€è¯­æ–™åº“ç­›é€‰ ---
    batch_text_all = " ".join([b['content'] for b in batch_blocks])
    relevant_glossary = filter_relevant_glossary(batch_text_all, glossary)
    glossary_text = json.dumps(relevant_glossary, ensure_ascii=False)

    # --- 1. ç›´è¯‘ (Literal) ---
    input_data = [{"id": int(b['index']), "text": b['content']} for b in batch_blocks]
    json_input = json.dumps(input_data, ensure_ascii=False, indent=2)

    msgs_trans = [{"role": "system", "content": PROMPT_TEMPLATES["LITERAL_TRANS"].format(
        glossary=glossary_text, json_input=json_input
    )}]

    trans_list = []
    # å¢åŠ ç»“æœæ ¡éªŒé‡è¯•é€»è¾‘
    for attempt in range(config.max_retries):
        raw_trans = await call_llm(config, msgs_trans, temperature=config.temp_literal)
        trans_list = clean_and_extract_json(raw_trans)
        
        # ç®€å•æ ¡éªŒï¼šå¦‚æœè¿”å›äº†éç©ºåˆ—è¡¨ï¼Œä¸”åŒ…å«åŸºæœ¬çš„ id/trans å­—æ®µï¼Œåˆ™è§†ä¸ºæˆåŠŸ
        if trans_list and isinstance(trans_list, list) and len(trans_list) > 0:
            break
        else:
            print(f"  [Warn] ç›´è¯‘ç»“æœè§£æå¤±è´¥æˆ–ä¸ºç©º (Attempt {attempt+1}/{config.max_retries})ï¼Œæ­£åœ¨é‡è¯•...")

    # å»ºç«‹ç›´è¯‘æ˜ å°„è¡¨ {id: text}
    literal_map = {}
    if isinstance(trans_list, list):
        for item in trans_list:
            if isinstance(item, dict) and 'id' in item and 'trans' in item:
                literal_map[str(item['id'])] = item['trans']
    
    return literal_map, glossary_text


async def process_polish_stage(batch_blocks: List[Dict], config, literal_map: Dict[str, str], glossary_text: str, previous_context: str = "", future_context: str = "") -> List[Dict]:
    """
    é˜¶æ®µ2ï¼šæ¶¦è‰²ï¼ˆä¾èµ–ä¸Šä¸‹æ–‡ï¼‰
    """
    # --- 2. æ¶¦è‰² (Polish) ---
    # æ„å»ºæ¶¦è‰²è¾“å…¥ï¼šåŒ…å«åŸæ–‡å’Œç›´è¯‘
    polish_input_data = []
    for b in batch_blocks:
        idx = str(b['index'])
        lit_text = literal_map.get(idx, b['content'])
        polish_input_data.append({
            "id": int(idx),
            "original": b['content'],
            "literal": lit_text
        })

    json_polish_input = json.dumps(polish_input_data, ensure_ascii=False, indent=2)

    # å¤„ç†ä¸Šä¸‹æ–‡çš„æƒ…å†µ
    context_to_send = previous_context if previous_context else "None (Beginning of file)."
    future_to_send = future_context if future_context else "None (End of file)."

    msgs_polish = [{"role": "system", "content": PROMPT_TEMPLATES["REVIEW_AND_POLISH"].format(
        glossary=glossary_text, 
        json_input=json_polish_input,
        previous_context=context_to_send,
        future_context=future_to_send
    )}]

    polish_list = []
    # å¢åŠ ç»“æœæ ¡éªŒé‡è¯•é€»è¾‘
    for attempt in range(config.max_retries):
        raw_polish = await call_llm(config, msgs_polish, temperature=config.temp_polish)
        polish_list = clean_and_extract_json(raw_polish)
        
        if polish_list and isinstance(polish_list, list) and len(polish_list) > 0:
            break
        else:
             print(f"  [Warn] æ¶¦è‰²ç»“æœè§£æå¤±è´¥æˆ–ä¸ºç©º (Attempt {attempt+1}/{config.max_retries})ï¼Œæ­£åœ¨é‡è¯•...")

    # å»ºç«‹æ¶¦è‰²æ˜ å°„è¡¨
    polish_map = {}
    if isinstance(polish_list, list):
        for item in polish_list:
            if isinstance(item, dict) and 'id' in item and 'polished' in item:
                polish_map[str(item['id'])] = item['polished']

    # --- 3. æœ€ç»ˆç»„è£… ---
    final_blocks = []

    for block in batch_blocks:
        idx = block['index']

        # ä¼˜å…ˆçº§ï¼šæ¶¦è‰²ç»“æœ > ç›´è¯‘ç»“æœ > åŸæ–‡
        if idx in polish_map and len(polish_map[idx]) > 0:
            final_text = polish_map[idx]
        elif idx in literal_map and len(literal_map[idx]) > 0:
            final_text = literal_map[idx]
            # åªæœ‰åœ¨ç›´è¯‘å’Œæ¶¦è‰²åŒé‡å¤±è´¥åï¼Œæ‰ä¼šæ‰“å°è¿™ä¸ª Info
            # print(f"  [Info] ID {idx} æ¶¦è‰²ä¸¢å¤±ï¼Œå›é€€åˆ°ç›´è¯‘") 
        else:
            final_text = block['content']
            print(f"  [Error] ID {idx} ç¿»è¯‘å®Œå…¨å¤±è´¥ï¼Œä¿ç•™åŸæ–‡") # åªæœ‰çœŸçš„å…¨æŒ‚äº†æ‰ Error

        final_blocks.append({
            "index": idx,
            "timestamp": block['timestamp'],
            "original": block['content'],
            "polished": final_text
        })

    return final_blocks
