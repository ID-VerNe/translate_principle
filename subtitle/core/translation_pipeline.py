# -*- coding: utf-8 -*- 

import json
from typing import List, Dict, Tuple

from .llm_client import call_llm, clean_and_extract_json
from .prompts import get_prompt_templates
# å¼•å…¥è¯­æ–™åº“ç®¡ç†å™¨
from .glossary_manager import glossary_manager

PROMPT_TEMPLATES = get_prompt_templates()

def filter_relevant_glossary(text_content: str, full_glossary: Dict[str, str]) -> Dict[str, str]:
    """
    ä»…ä¿ç•™åœ¨å½“å‰æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­ï¼Œå‡å°‘ Token æ¶ˆè€—å¹¶èšç„¦æ³¨æ„åŠ›ã€‚
    """
    relevant = {}
    text_lower = text_content.lower()
    for src, tgt in full_glossary.items():
        if src.lower() in text_lower:
            relevant[src] = tgt
    return relevant

async def extract_global_terms(config, blocks: List[Dict]) -> Dict[str, str]:
    """
    æå–æœ¯è¯­ï¼ˆæ··åˆæ¨¡å¼ï¼šå†å²è¯­æ–™åº“åŒ¹é… + LLM æ–°æœ¯è¯­å‘ç°ï¼‰
    """
    print("=== Step 1: æ„å»ºæœ¯è¯­è¡¨ ===")
    
    # 1. æ‹¼æ¥å…¨æ–‡
    full_text = "\n".join([b['content'] for b in blocks])
    
    # 2. ä»å†å²è¯­æ–™åº“ä¸­åŒ¹é… (åŸºäº FlashTextï¼Œé€Ÿåº¦æå¿«)
    print("  æ­£åœ¨æ£€ç´¢å†å²è¯­æ–™åº“...")
    historical_glossary = glossary_manager.extract_terms(full_text)
    print(f"  ğŸ“– åŒ¹é…åˆ° {len(historical_glossary)} ä¸ªå†å²å›ºå®šæœ¯è¯­")

    # 3. ä½¿ç”¨ LLM å‘ç°æ–°æœ¯è¯­ (é‡‡æ ·å¤„ç†)
    print("  æ­£åœ¨ä½¿ç”¨ LLM å‘ç°æ–°æœ¯è¯­...")
    sampled_text = ""
    # ç¨å¾®å¢åŠ é‡‡æ ·å¯†åº¦ï¼Œæ¯5è¡Œé‡‡ä¸€è¡Œï¼Œæˆ–è€…å–å‰ä¸­å
    for i in range(0, len(blocks), 5): 
        sampled_text += blocks[i]['content'] + "\n"
    
    if len(sampled_text) > 3000:
        sampled_text = sampled_text[:3000]

    messages = [{"role": "system", "content": PROMPT_TEMPLATES["TERM_EXTRACT"].format(content=sampled_text)}]
    
    # è¿™é‡Œçš„ temperature ä½ä¸€ç‚¹ï¼Œå‡å°‘å¹»è§‰
    result = await call_llm(config, messages, temperature=config.temp_terms)
    
    llm_glossary = {}
    data = clean_and_extract_json(result)
    if isinstance(data, dict):
        llm_glossary = data
    
    print(f"  ğŸ¤– LLM å‘ç°äº† {len(llm_glossary)} ä¸ªæ–°æœ¯è¯­")

    # 4. åˆå¹¶æœ¯è¯­è¡¨
    # ç­–ç•¥ï¼šå†å²æœ¯è¯­è¦†ç›– LLM æå–çš„æœ¯è¯­ (History is Truth)
    # è¿™æ ·å¯ä»¥ä¿®æ­£ LLM å¯èƒ½äº§ç”Ÿçš„é”™è¯¯å¹»è§‰ï¼Œä¿æŒç³»åˆ—ä¸€è‡´æ€§
    final_glossary = {**llm_glossary, **historical_glossary}
    
    print(f"  âœ… æœ€ç»ˆæœ¯è¯­è¡¨åŒ…å« {len(final_glossary)} æ¡ç›®")
    return final_glossary


async def process_literal_stage(batch_blocks: List[Dict], config, glossary: Dict[str, str]) -> Tuple[Dict[str, str], str]:
    """
    é˜¶æ®µ1ï¼šç›´è¯‘ä¸æœ¯è¯­å‡†å¤‡ï¼ˆä¸Šä¸‹æ–‡æ— å…³ï¼Œå¯å¹¶è¡Œï¼‰
    è¿”å›: (literal_map, glossary_text)
    """
    # --- 0. åŠ¨æ€è¯­æ–™åº“ç­›é€‰ ---
    batch_text_all = " ".join([b['content'] for b in batch_blocks])
    relevant_glossary = filter_relevant_glossary(batch_text_all, glossary)
    glossary_text = json.dumps(relevant_glossary, ensure_ascii=False)

    # --- 1. ç›´è¯‘ (Literal) ---
    input_data = [{"id": int(b['index']), "text": b['content']} for b in batch_blocks]
    json_input = json.dumps(input_data, ensure_ascii=False, indent=2)

    msgs_trans = [{"role": "system", "content": PROMPT_TEMPLATES["LITERAL_TRANS"].format(
        glossary=glossary_text, json_input=json_input
    )}]

    trans_list = []
    # å¢åŠ ç»“æœæ ¡éªŒé‡è¯•é€»è¾‘
    for attempt in range(config.max_retries):
        raw_trans = await call_llm(config, msgs_trans, temperature=config.temp_literal)
        trans_list = clean_and_extract_json(raw_trans)
        
        # ç®€å•æ ¡éªŒï¼šå¦‚æœè¿”å›äº†éç©ºåˆ—è¡¨ï¼Œä¸”åŒ…å«åŸºæœ¬çš„ id/trans å­—æ®µï¼Œåˆ™è§†ä¸ºæˆåŠŸ
        if trans_list and isinstance(trans_list, list) and len(trans_list) > 0:
            break
        else:
            print(f"  [Warn] ç›´è¯‘ç»“æœè§£æå¤±è´¥æˆ–ä¸ºç©º (Attempt {attempt+1}/{config.max_retries})ï¼Œæ­£åœ¨é‡è¯•...")

    # å»ºç«‹ç›´è¯‘æ˜ å°„è¡¨ {id: text}
    literal_map = {}
    if isinstance(trans_list, list):
        for item in trans_list:
            if isinstance(item, dict) and 'id' in item and 'trans' in item:
                literal_map[str(item['id'])] = item['trans']
    
    return literal_map, glossary_text


async def process_polish_stage(batch_blocks: List[Dict], config, literal_map: Dict[str, str], glossary_text: str, previous_context: str = "") -> List[Dict]:
    """
    é˜¶æ®µ2ï¼šæ¶¦è‰²ï¼ˆä¾èµ–ä¸Šæ–‡ï¼Œå¿…é¡»ä¸²è¡Œï¼‰
    """
    # --- 2. æ¶¦è‰² (Polish) ---
    # æ„å»ºæ¶¦è‰²è¾“å…¥ï¼šåŒ…å«åŸæ–‡å’Œç›´è¯‘
    polish_input_data = []
    for b in batch_blocks:
        idx = str(b['index'])
        # å³ä½¿ç›´è¯‘å¤±è´¥ï¼Œä¹ŸæŠŠåŸæ–‡æ”¾è¿›å»ï¼Œé˜²æ­¢æ–­æ¡£
        lit_text = literal_map.get(idx, b['content'])
        polish_input_data.append({
            "id": int(idx),
            "original": b['content'],
            "literal": lit_text
        })

    json_polish_input = json.dumps(polish_input_data, ensure_ascii=False, indent=2)

    # å¤„ç†ç©ºä¸Šä¸‹æ–‡çš„æƒ…å†µ
    context_to_send = previous_context if previous_context else "None (Beginning of file, please establish the translation style)."

    msgs_polish = [{"role": "system", "content": PROMPT_TEMPLATES["REVIEW_AND_POLISH"].format(
        glossary=glossary_text, 
        json_input=json_polish_input,
        previous_context=context_to_send
    )}]

    polish_list = []
    # å¢åŠ ç»“æœæ ¡éªŒé‡è¯•é€»è¾‘
    for attempt in range(config.max_retries):
        raw_polish = await call_llm(config, msgs_polish, temperature=config.temp_polish)
        polish_list = clean_and_extract_json(raw_polish)
        
        if polish_list and isinstance(polish_list, list) and len(polish_list) > 0:
            break
        else:
             print(f"  [Warn] æ¶¦è‰²ç»“æœè§£æå¤±è´¥æˆ–ä¸ºç©º (Attempt {attempt+1}/{config.max_retries})ï¼Œæ­£åœ¨é‡è¯•...")

    # å»ºç«‹æ¶¦è‰²æ˜ å°„è¡¨
    polish_map = {}
    if isinstance(polish_list, list):
        for item in polish_list:
            if isinstance(item, dict) and 'id' in item and 'polished' in item:
                polish_map[str(item['id'])] = item['polished']

    # --- 3. æœ€ç»ˆç»„è£… ---
    final_blocks = []

    for block in batch_blocks:
        idx = block['index']

        # ä¼˜å…ˆçº§ï¼šæ¶¦è‰²ç»“æœ > ç›´è¯‘ç»“æœ > åŸæ–‡
        if idx in polish_map and len(polish_map[idx]) > 0:
            final_text = polish_map[idx]
        elif idx in literal_map and len(literal_map[idx]) > 0:
            final_text = literal_map[idx]
            # åªæœ‰åœ¨ç›´è¯‘å’Œæ¶¦è‰²åŒé‡å¤±è´¥åï¼Œæ‰ä¼šæ‰“å°è¿™ä¸ª Info
            # print(f"  [Info] ID {idx} æ¶¦è‰²ä¸¢å¤±ï¼Œå›é€€åˆ°ç›´è¯‘") 
        else:
            final_text = block['content']
            print(f"  [Error] ID {idx} ç¿»è¯‘å®Œå…¨å¤±è´¥ï¼Œä¿ç•™åŸæ–‡") # åªæœ‰çœŸçš„å…¨æŒ‚äº†æ‰ Error

        final_blocks.append({
            "index": idx,
            "timestamp": block['timestamp'],
            "original": block['content'],
            "polished": final_text
        })

    return final_blocks
