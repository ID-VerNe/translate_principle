# 📚 语料库构建指南

为了确保翻译的一致性（尤其是人名、专有名词、特定梗），我们需要构建一个高质量的本地语料库。

本目录提供了一套**"提取 -> AI 识别 -> 入库"**的完整工具链，帮助你利用已有的字幕文件（`.srt` / `.ass`）快速扩充语料库。

---

## 🚀 快速上手 (三步走)

### 第一步：从旧字幕提取双语素材

如果你手头有已经翻译好的字幕文件（例如以前的剧集），可以使用 `glossary_tool.py` 将它们转换为 AI 易于阅读的双语文本格式。

1.  将你的 `.srt` 或 `.ass` 文件放入 `subtitle/glossaries/` 目录（或其子目录）下的任意位置。
2.  运行提取工具：
    ```powershell
    python glossary_tool.py
    ```
3.  **结果**：脚本会在每个字幕文件旁边生成一个同名的 `.txt` 文件，内容格式为“一行英文，一行中文”。

### 第二步：使用 AI 提取术语

有了双语文本后，我们需要让 AI 帮我们把里面的“精华”（术语、人名）挑出来。

1.  **复制 Prompt**：打开 `prompt.md`，复制里面的全部内容。
2.  **复制文本**：打开上一步生成的 `.txt` 文件，复制一部分内容（建议每次复制 50-100 行，避免超出 AI 上下文限制）。
3.  **发送给 AI**：
    *   在 ChatGPT / Claude / Gemini 中新建对话。
    *   粘贴 `prompt.md` 的内容。
    *   粘贴你复制的双语文本。
    *   发送。
4.  **获取结果**：AI 会返回一段 JSON 格式的数据（即提取出的术语表）。

### 第三步：入库与管理

AI 返回的 JSON 需要经过校验、去重和格式化才能存入语料库。我们提供了一个图形化工具来完成这一步。

1.  运行管理工具：
    ```powershell
    python glossary_gui.py
    ```
2.  **导入数据**：
    *   复制 AI 返回的 JSON 代码块（包括 `[` 和 `]`）。
    *   在工具中点击 **"📋 读取剪贴板并去重"**。
    *   工具会自动过滤掉已经存在的术语，并修正一些简单的格式错误。
3.  **人工微调**：
    *   在中间的文本框中，你可以手动修改翻译不准确的地方，或者删除不需要的词条。
4.  **保存**：
    *   点击 **"💾 保存为新文件"**。
    *   工具会自动生成一个新的数字编号文件（如 `1.json`, `2.json`），永久存入语料库。

---

## 📂 文件说明

*   **`glossary_gui.py`**: 语料库管理工具（图形界面）。支持剪贴板导入、自动去重、手动添加和保存。
*   **`glossary_tool.py`**: 字幕提取工具。递归扫描目录，将 `.ass/.srt` 转换为适合 LLM 阅读的双语 `.txt`。
*   **`prompt.md`**: 专门用于提取术语的 System Prompt，配合 LLM 使用。
*   **`test.json`**: 语料库文件示例。你的所有语料库文件都应遵循此格式。
*   **`字幕/`**: 推荐将你的旧字幕文件分类存放在此文件夹中，保持整洁。

## 💡 最佳实践

*   **少量多次**：不要一次性把几万行的字幕发给 AI，分段处理效果更好。
*   **人工把关**：AI 可能会提取出一些通用词汇（如 "Car"），在入库前请在 GUI 工具中手动删除这些“废话”。
*   **定期备份**：生成的 `.json` 文件是你的核心资产，建议定期备份。
